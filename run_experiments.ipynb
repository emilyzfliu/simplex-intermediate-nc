{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRfiDNPRllbi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J7K2hZVllbj"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmwbIAg6llbl"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "batch_size = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OsD96Uwllbl"
      },
      "source": [
        "#### CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZQyQWABllbl",
        "outputId": "493778ac-fbba-4fe8-ff08-2b78074c82b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset_10 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader_10 = torch.utils.data.DataLoader(trainset_10, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset_10 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader_10 = torch.utils.data.DataLoader(testset_10, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6byZ10o-llbn"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu0xYQ3Yllbn"
      },
      "source": [
        "MLP-L-H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zsX9XUzllbo"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, L, H, fixdim, simplex):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    layers = [nn.Linear(3072, H)]\n",
        "    bns = [nn.BatchNorm1d(H)]\n",
        "\n",
        "    num_classes = 10\n",
        "\n",
        "    for i in range(L-2):\n",
        "      layers.append(nn.Linear(H, H))\n",
        "      bns.append(nn.BatchNorm1d(H))\n",
        "        \n",
        "    if fixdim:\n",
        "      layers.append(nn.Linear(H, num_classes))\n",
        "      self.fc_out= nn.Linear(num_classes, num_classes)\n",
        "    else:\n",
        "      layers.append(nn.Linear(H, H))\n",
        "      nn.Linear(H, num_classes)\n",
        "    \n",
        "    bns.append(nn.BatchNorm1d(H))\n",
        "\n",
        "    self.fcs = nn.ModuleList(layers)\n",
        "    self.bns = nn.ModuleList(bns)\n",
        "\n",
        "    if simplex:\n",
        "      weight = torch.sqrt(torch.tensor(num_classes/(num_classes-1)))*(torch.eye(num_classes)-(1/num_classes)*torch.ones((num_classes, num_classes)))\n",
        "      weight /= torch.sqrt((1/num_classes*torch.norm(weight, 'fro')**2))\n",
        "      if fixdim:\n",
        "        self.fc_out.weight = nn.Parameter(weight)\n",
        "      else:\n",
        "        self.fc_out.weight = nn.Parameter(torch.mm(weight, torch.eye(num_classes, H)))\n",
        "      self.fc_out.weight.requires_grad_(False)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        for layer, bn in zip(self.fcs, self.bns):\n",
        "            h = self.relu(bn(layer(h)))\n",
        "        return self.fc_out(h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOTAL-s6llbo"
      },
      "source": [
        "CONV-L-H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u19V9Ehillbo"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFJ3DpQTllbp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "846d7c97c30a6049968d1d1a6818eafdf2eb941006d2719374ee3821acbef096"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}